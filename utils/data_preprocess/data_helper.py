#!/usr/bin/env python
# encoding: utf-8
"""
    @Time: 2021/4/9 15:32
    @File: data_helper.py
    @Desc:
    @Reference: 
    @Author: letter
    @Contact: 5403517@qq.com
"""

import re

from utils.data_preprocess.data.langconv import *


class TextClear:
    def __init__(self):
        # åŠ è½½æ­£åˆ™ç¼–è¯‘å™¨
        """
            å¦‚æœä¸ä½¿ç”¨re.Så‚æ•°ï¼Œåˆ™åªåœ¨æ¯ä¸€è¡Œå†…è¿›è¡ŒåŒ¹é…ï¼Œå¦‚æœä¸€è¡Œæ²¡æœ‰ï¼Œå°±æ¢ä¸‹ä¸€è¡Œé‡æ–°å¼€å§‹ã€‚
            è€Œä½¿ç”¨re.Så‚æ•°ä»¥åï¼Œæ­£åˆ™è¡¨è¾¾å¼ä¼šå°†è¿™ä¸ªå­—ç¬¦ä¸²ä½œä¸ºä¸€ä¸ªæ•´ä½“ï¼Œåœ¨æ•´ä½“ä¸­è¿›è¡ŒåŒ¹é…ã€‚
        """
        self.re_que_punc = re.compile(r"[?ï¼Ÿ]+")
        self.re_cn = re.compile(r'[\u4e00-\u9fa5]')
        self.re_time = re.compile(r"\d+-\d+-\d+\s+\d+:\d+")

        self.re_punc = re.compile(
            r"[,.ï¼Œâ€“\'ã€‚â‰§â–½Ï‰â‰¦Ğ·ã€âˆ ï¼ï½œ|ï¼Â°^ï¼œï¼ã€‰{}ï¼ğŸ˜ŠğŸ˜„ã„›ä¸¨â‹¯ï¼…ğŸ˜­ğŸ˜³ğŸ˜ ï¼›*ï¼‚=ï¼ã€ã€ğŸ˜ã€Œâ†’ï½â€”ï¿¥ï¼‹Ã—âˆ©â•­â•®`~$%â€¦&:ï¼š!ï¼ã€ã€‘@â€˜â€™â€œâ€\-_\\/ã€\]\[#+~Â·ã€Šã€‹()ï¼ˆï¼‰]+")

        self.re_eng = re.compile(r'[a-zA-Z]+')
        self.re_float = re.compile(r'\d+\.\d+')
        self.re_digit = re.compile(r'\d+')
        self.re_http = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')
        self.re_forward = re.compile("@.*?: ", re.S)
        self.re_emoji = re.compile(r"\[.*?]", re.S)
        self.re_at = re.compile("@.*?( |:)", re.S)
        self.re_yuanweibo = re.compile(r"ã€åŸå¾®åšã€‘", re.S)
        self.re_http_tag = re.compile(r"<.*>")

        self.re_hard = re.compile(r"â€‹â€‹", re.S)

    def clear_for_words(self, sentence):
        '''

            :param text_list:  ["ä¸€æ®µæ–‡æœ¬", "ç¬¬äºŒæ®µæ–‡æœ¬"]
            :return:           åŒä¸Š
        '''

        # the precess is ordered
        # remove  < >
        sentence = self.base_bert_clear(sentence, seq_len=512)
        sentence = sentence.replace('<', 'ã€Š').replace('>', 'ã€‹').replace(' ', '')
        sentence = sentence.lower().replace('samsung', 'ä¸‰æ˜Ÿ').replace('xiaomi', 'å°ç±³').replace('huawei', 'åä¸º') \
            .replace('apple', 'è‹¹æœ').replace('honor', 'è£è€€').replace('redmi', 'çº¢ç±³') \
            .replace('meizu', 'é­…æ—').replace('sanxing', 'ä¸‰æ˜Ÿ') \
            .replace('Galaxy', 'ä¸‰æ˜Ÿç›–ä¹ä¸–').replace('iphone', 'è‹¹æœæ‰‹æœº')
        sentence = re.sub(self.re_eng, '<eng>', sentence)
        sentence = re.sub(self.re_float, '<flt>', sentence)
        sentence = re.sub(self.re_digit, '<dgt>', sentence)
        sentence = re.sub(self.re_punc, '<punc>', sentence)
        sentence = re.sub(self.re_que_punc, '<que>', sentence)
        return sentence

    def base_bert_clear(self, sentence, seq_len=128):
        """
        clear text for bert
        Args:
            sentence:
            seq_len:
        Returns:
        """
        sentence = self.tradition_to_simple(sentence)
        sentence = re.sub(self.re_hard, "", sentence)
        sentence = self.delete_http_tag(sentence)
        sentence = self.delete_none(sentence)
        sentence = self.delete_emoji(sentence)
        sentence = self.delete_at(sentence)
        sentence = self.delete_http(sentence)

        return sentence[:seq_len]

    def replace_eng(self, sentence):
        sentence = re.sub(self.re_eng, 'e', sentence)
        return sentence

    def delete_http_tag(self, sentence):
        sentence = re.sub(self.re_http_tag, '', sentence)
        return sentence

    @staticmethod
    def delete_zhuanfa(sentence):
        sentence = re.sub(r"è½¬å‘å¾®åš", "", sentence)
        return sentence

    def delete_time(self, sentence):
        sentence = re.sub(self.re_time, "", sentence)
        return sentence

    def delete_at(self, sentence):
        sentence = re.sub(self.re_at, "", sentence)
        return sentence

    @staticmethod
    def delete_none(sentence: str):
        """åˆ é™¤ç©ºç™½,ç©ºæ ¼"""
        return sentence.replace(' ', '').replace('\t', '').replace('</br>', '').replace('\u200b', '').replace('\n', 'ï¼Œ')

    def delete_http(self, sentence):
        sentence = re.sub(self.re_http, "", sentence)
        return sentence

    def delete_emoji(self, sentence):
        return re.sub(self.re_emoji, "", sentence)

    @staticmethod
    def tradition_to_simple(text: str):
        """ç¹ä½“è½¬ç®€ä½“"""
        text = Converter('zh-hans').convert(text)
        return text

    @staticmethod
    def wordsDeduplication(word_list: list):
        """
            è¯å»é‡
        Args:
            word_list: ['ä¸­åæ°‘æ—ä¼Ÿå¤§', 'æ°‘æ—ä¼Ÿå¤§']
        Returns:
            list: ['ä¸­åæ°‘æ—ä¼Ÿå¤§']
        """
        # å…ˆsetå»é‡ï¼ŒæŒ‰ç…§é•¿åº¦é™åº
        word_list = sorted(list(set(word_list)), key=lambda x: len(x), reverse=True)
        words_num = len(word_list)
        if words_num < 2:
            # åˆ¤æ–­è¯çš„ä¸ªæ•°
            return word_list

        rtn_word_list = []
        for i in range(words_num):
            for j in range(words_num):
                if i == j:  # ä¸å’Œè‡ªèº«æ¯”è¾ƒ
                    continue
                if word_list[i] in word_list[j]:
                    # å’Œå…¶ä»–è¯æ¯”è¾ƒæ˜¯å¦é‡å¤
                    # å¦‚æœé‡å¤ï¼Œç›´æ¥è·³å‡ºï¼Œä¸ä¿å­˜è¯¥è¯
                    break
            # æ— é‡å¤ï¼Œä¿å­˜è¯¥è¯
            if j == words_num - 1:
                rtn_word_list.append(word_list[i])

        return rtn_word_list


# t = TextClear()
